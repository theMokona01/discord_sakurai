"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const check_package_1 = require("@pnpm/check-package");
const core_loggers_1 = require("@pnpm/core-loggers");
const logger_1 = require("@pnpm/logger");
const pkgid_to_filename_1 = require("@pnpm/pkgid-to-filename");
const read_package_json_1 = require("@pnpm/read-package-json");
const load_json_file_1 = require("load-json-file");
const mkdirp = require("mkdirp-promise");
const fs = require("mz/fs");
const PQueue = require("p-queue");
const path = require("path");
const exists = require("path-exists");
const renameOverwrite = require("rename-overwrite");
const rimraf = require("rimraf-then");
const symlinkDir = require("symlink-dir");
const write_json_file_1 = require("write-json-file");
const TARBALL_INTEGRITY_FILENAME = 'tarball-integrity';
function default_1(resolve, fetchers, opts) {
    opts = opts || {};
    const networkConcurrency = opts.networkConcurrency || 16;
    const requestsQueue = new PQueue({
        concurrency: networkConcurrency,
    });
    requestsQueue['counter'] = 0; // tslint:disable-line
    requestsQueue['concurrency'] = networkConcurrency; // tslint:disable-line
    const fetch = fetcher.bind(null, fetchers);
    const fetchPackageToStore = fetchToStore.bind(null, {
        fetch,
        fetchingLocker: new Map(),
        requestsQueue,
        storeIndex: opts.storeIndex,
        storePath: opts.storePath,
        verifyStoreIntegrity: opts.verifyStoreIntegrity,
    });
    const requestPackage = resolveAndFetch.bind(null, {
        fetchPackageToStore,
        requestsQueue,
        resolve,
        storePath: opts.storePath,
        verifyStoreIntegrity: opts.verifyStoreIntegrity,
    });
    requestPackage['requestPackage'] = requestPackage; // tslint:disable-line
    requestPackage['fetchPackageToStore'] = fetchPackageToStore; // tslint:disable-line
    return requestPackage;
}
exports.default = default_1;
async function resolveAndFetch(ctx, wantedDependency, options) {
    try {
        let latest;
        let pkg;
        let normalizedPref;
        let resolution = options.currentResolution;
        let pkgId = options.currentPackageId;
        const skipResolution = resolution && !options.update;
        let forceFetch = false;
        let updated = false;
        let resolvedVia;
        // When fetching is skipped, resolution cannot be skipped.
        // We need the package's manifest when doing `lockfile-only` installs.
        // When we don't fetch, the only way to get the package's manifest is via resolving it.
        //
        // The resolution step is never skipped for local dependencies.
        if (!skipResolution || options.skipFetch || pkgId && pkgId.startsWith('file:')) {
            const resolveResult = await ctx.requestsQueue.add(() => ctx.resolve(wantedDependency, {
                defaultTag: options.defaultTag,
                localPackages: options.localPackages,
                lockfileDirectory: options.lockfileDirectory,
                preferredVersions: options.preferredVersions,
                prefix: options.prefix,
                registry: options.registry,
            }), { priority: options.downloadPriority });
            pkg = resolveResult.package;
            latest = resolveResult.latest;
            resolvedVia = resolveResult.resolvedVia;
            // If the integrity of a local tarball dependency has changed,
            // the local tarball should be unpacked, so a fetch to the store should be forced
            forceFetch = Boolean(options.currentResolution &&
                pkgId && pkgId.startsWith('file:') &&
                options.currentResolution['integrity'] !== resolveResult.resolution['integrity']);
            if (!skipResolution || forceFetch) {
                updated = pkgId !== resolveResult.id || !resolution || forceFetch;
                // Keep the lockfile resolution when possible
                // to keep the original shasum.
                if (updated) {
                    resolution = resolveResult.resolution;
                }
                pkgId = resolveResult.id;
                normalizedPref = resolveResult.normalizedPref;
            }
        }
        const id = pkgId;
        if (resolution.type === 'directory') {
            if (!pkg) {
                throw new Error(`Couldn't read package.json of local dependency ${wantedDependency.alias ? wantedDependency.alias + '@' : ''}${wantedDependency.pref}`);
            }
            return {
                body: {
                    cacheByEngine: options.sideEffectsCache ? await getCacheByEngine(ctx.storePath, id) : new Map(),
                    id,
                    isLocal: true,
                    manifest: pkg,
                    normalizedPref,
                    resolution: resolution,
                    resolvedVia,
                    updated,
                },
            };
        }
        // We can skip fetching the package only if the manifest
        // is present after resolution
        if (options.skipFetch && pkg) {
            return {
                body: {
                    cacheByEngine: options.sideEffectsCache ? await getCacheByEngine(ctx.storePath, id) : new Map(),
                    id,
                    inStoreLocation: path.join(ctx.storePath, pkgid_to_filename_1.default(id, options.lockfileDirectory)),
                    isLocal: false,
                    latest,
                    manifest: pkg,
                    normalizedPref,
                    resolution,
                    resolvedVia,
                    updated,
                },
            };
        }
        const fetchResult = ctx.fetchPackageToStore({
            fetchRawManifest: updated || !pkg,
            force: forceFetch,
            pkgId: id,
            pkgName: pkg && pkg.name,
            prefix: options.lockfileDirectory,
            resolution: resolution,
        });
        return {
            body: {
                cacheByEngine: options.sideEffectsCache ? await getCacheByEngine(ctx.storePath, id) : new Map(),
                id,
                inStoreLocation: fetchResult.inStoreLocation,
                isLocal: false,
                latest,
                manifest: pkg,
                normalizedPref,
                resolution,
                resolvedVia,
                updated,
            },
            fetchingFiles: fetchResult.fetchingFiles,
            fetchingRawManifest: fetchResult.fetchingRawManifest,
            finishing: fetchResult.finishing,
        };
    }
    catch (err) {
        throw err;
    }
}
function fetchToStore(ctx, opts) {
    const targetRelative = pkgid_to_filename_1.default(opts.pkgId, opts.prefix);
    const target = path.join(ctx.storePath, targetRelative);
    if (!ctx.fetchingLocker.has(opts.pkgId)) {
        const fetchingRawManifest = differed();
        const fetchingFiles = differed();
        const finishing = differed();
        doFetchToStore(fetchingRawManifest, fetchingFiles, finishing); // tslint:disable-line
        if (opts.fetchRawManifest) {
            ctx.fetchingLocker.set(opts.pkgId, {
                fetchingFiles: removeKeyOnFail(fetchingFiles.promise),
                fetchingRawManifest: removeKeyOnFail(fetchingRawManifest.promise),
                finishing: removeKeyOnFail(finishing.promise),
                inStoreLocation: target,
            });
        }
        else {
            ctx.fetchingLocker.set(opts.pkgId, {
                fetchingFiles: removeKeyOnFail(fetchingFiles.promise),
                finishing: removeKeyOnFail(finishing.promise),
                inStoreLocation: target,
            });
        }
        // When fetchingFiles resolves, the cached result has to set fromStore to true, without
        // affecting previous invocations: so we need to replace the cache.
        //
        // Changing the value of fromStore is needed for correct reporting of `pnpm server`.
        // Otherwise, if a package was not in store when the server started, it will be always
        // reported as "downloaded" instead of "reused".
        fetchingFiles.promise.then(({ filenames, fromStore }) => {
            // If it's already in the store, we don't need to update the cache
            if (fromStore) {
                return;
            }
            const tmp = ctx.fetchingLocker.get(opts.pkgId);
            // If fetching failed then it was removed from the cache.
            // It is OK. In that case there is no need to update it.
            if (!tmp)
                return;
            ctx.fetchingLocker.set(opts.pkgId, {
                fetchingFiles: Promise.resolve({
                    filenames,
                    fromStore: true,
                }),
                fetchingRawManifest: tmp.fetchingRawManifest,
                finishing: tmp.finishing,
                inStoreLocation: tmp.inStoreLocation,
            });
        });
        fetchingFiles.promise.catch((err) => {
            ctx.fetchingLocker.delete(opts.pkgId);
            throw err;
        });
    }
    const result = ctx.fetchingLocker.get(opts.pkgId);
    if (opts.fetchRawManifest && !result.fetchingRawManifest) {
        result.fetchingRawManifest = removeKeyOnFail(result.fetchingFiles.then(() => read_package_json_1.fromDir(path.join(result.inStoreLocation, 'package'))));
    }
    return result;
    function removeKeyOnFail(p) {
        return p.catch((err) => {
            ctx.fetchingLocker.delete(opts.pkgId);
            throw err;
        });
    }
    async function doFetchToStore(fetchingRawManifest, fetchingFiles, finishing) {
        try {
            const isLocalTarballDep = opts.pkgId.startsWith('file:');
            const linkToUnpacked = path.join(target, 'package');
            // We can safely assume that if there is no data about the package in `store.json` then
            // it is not in the store yet.
            // In case there is record about the package in `store.json`, we check it in the file system just in case
            const targetExists = ctx.storeIndex[targetRelative] && await exists(path.join(linkToUnpacked, 'package.json'));
            if (!opts.force && targetExists &&
                (isLocalTarballDep === false ||
                    opts.resolution['integrity'] && await tarballSatisfiesIntegrity(opts.resolution['integrity'], target) // tslint:disable-line:no-string-literal
                )) {
                // if target exists and it wasn't modified, then no need to refetch it
                const satisfiedIntegrity = ctx.verifyStoreIntegrity
                    ? await check_package_1.default(linkToUnpacked)
                    : await load_json_file_1.default(path.join(path.dirname(linkToUnpacked), 'integrity.json'));
                if (satisfiedIntegrity) {
                    fetchingFiles.resolve({
                        filenames: Object.keys(satisfiedIntegrity).filter((f) => !satisfiedIntegrity[f].isDir),
                        fromStore: true,
                    });
                    if (opts.fetchRawManifest) {
                        read_package_json_1.fromDir(linkToUnpacked)
                            .then(fetchingRawManifest.resolve)
                            .catch(fetchingRawManifest.reject);
                    }
                    finishing.resolve(undefined);
                    return;
                }
                logger_1.storeLogger.warn(`Refetching ${target} to store. It was either modified or had no integrity checksums`);
            }
            // We fetch into targetStage directory first and then fs.rename() it to the
            // target directory.
            let filesIndex;
            let tempLocation;
            await Promise.all([
                (async () => {
                    // Tarballs are requested first because they are bigger than metadata files.
                    // However, when one line is left available, allow it to be picked up by a metadata request.
                    // This is done in order to avoid situations when tarballs are downloaded in chunks
                    // As much tarballs should be downloaded simultaneously as possible.
                    const priority = (++ctx.requestsQueue['counter'] % ctx.requestsQueue['concurrency'] === 0 ? -1 : 1) * 1000; // tslint:disable-line
                    const fetchedPackage = await ctx.requestsQueue.add(() => ctx.fetch(opts.pkgId, opts.resolution, target, {
                        cachedTarballLocation: path.join(ctx.storePath, opts.pkgId, 'packed.tgz'),
                        onProgress: (downloaded) => {
                            core_loggers_1.fetchingProgressLogger.debug({
                                downloaded,
                                packageId: opts.pkgId,
                                status: 'in_progress',
                            });
                        },
                        onStart: (size, attempt) => {
                            core_loggers_1.fetchingProgressLogger.debug({
                                attempt,
                                packageId: opts.pkgId,
                                size,
                                status: 'started',
                            });
                        },
                        prefix: opts.prefix,
                    }), { priority });
                    filesIndex = fetchedPackage.filesIndex;
                    tempLocation = fetchedPackage.tempLocation;
                })(),
                // removing only the folder with the unpacked files
                // not touching tarball and integrity.json
                targetExists && await rimraf(path.join(target, 'node_modules')),
            ]);
            // Ideally, fetchingFiles wouldn't care about when integrity is calculated.
            // However, we can only rename the temp folder once we know the package name.
            // And we cannot rename the temp folder till we're calculating integrities.
            if (ctx.verifyStoreIntegrity) {
                const fileIntegrities = await Promise.all(Object.keys(filesIndex)
                    .map((filename) => filesIndex[filename].generatingIntegrity
                    .then((fileIntegrity) => ({
                    [filename]: {
                        integrity: fileIntegrity,
                        size: filesIndex[filename].size,
                    },
                }))));
                const integrity = fileIntegrities
                    .reduce((acc, info) => {
                    Object.assign(acc, info);
                    return acc;
                }, {});
                await write_json_file_1.default(path.join(target, 'integrity.json'), integrity, { indent: null });
            }
            else {
                // TODO: save only filename: {size}
                await write_json_file_1.default(path.join(target, 'integrity.json'), filesIndex, { indent: null });
            }
            finishing.resolve(undefined);
            let pkgName = opts.pkgName;
            if (!pkgName || opts.fetchRawManifest) {
                const pkg = await read_package_json_1.fromDir(tempLocation);
                fetchingRawManifest.resolve(pkg);
                if (!pkgName) {
                    pkgName = pkg.name;
                }
            }
            const unpacked = path.join(target, 'node_modules', pkgName);
            await mkdirp(path.dirname(unpacked));
            // rename(oldPath, newPath) is an atomic operation, so we do it at the
            // end
            await renameOverwrite(tempLocation, unpacked);
            await symlinkDir(unpacked, linkToUnpacked);
            if (isLocalTarballDep && opts.resolution['integrity']) { // tslint:disable-line:no-string-literal
                await fs.writeFile(path.join(target, TARBALL_INTEGRITY_FILENAME), opts.resolution['integrity'], 'utf8'); // tslint:disable-line:no-string-literal
            }
            ctx.storeIndex[targetRelative] = ctx.storeIndex[targetRelative] || [];
            fetchingFiles.resolve({
                filenames: Object.keys(filesIndex).filter((f) => !filesIndex[f].isDir),
                fromStore: false,
            });
        }
        catch (err) {
            fetchingFiles.reject(err);
            if (opts.fetchRawManifest) {
                fetchingRawManifest.reject(err);
            }
        }
    }
}
async function tarballSatisfiesIntegrity(wantedIntegrity, pkgInStoreLocation) {
    try {
        const currentIntegrity = (await fs.readFile(path.join(pkgInStoreLocation, TARBALL_INTEGRITY_FILENAME), 'utf8'));
        return currentIntegrity === wantedIntegrity;
    }
    catch (err) {
        return false;
    }
}
// tslint:disable-next-line
function noop() { }
function differed() {
    let pResolve = noop;
    let pReject = noop;
    const promise = new Promise((resolve, reject) => {
        pResolve = resolve;
        pReject = reject;
    });
    return {
        promise,
        reject: pReject,
        resolve: pResolve,
    };
}
async function fetcher(fetcherByHostingType, packageId, resolution, target, opts) {
    const fetch = fetcherByHostingType[resolution.type || 'tarball'];
    if (!fetch) {
        throw new Error(`Fetching for dependency type "${resolution.type}" is not supported`);
    }
    try {
        return await fetch(resolution, target, opts);
    }
    catch (err) {
        logger_1.storeLogger.warn(`Fetching ${packageId} failed!`);
        throw err;
    }
}
// TODO: cover with tests
async function getCacheByEngine(storePath, id) {
    const map = new Map();
    const cacheRoot = path.join(storePath, id, 'side_effects');
    if (!await fs.exists(cacheRoot)) {
        return map;
    }
    const dirContents = (await fs.readdir(cacheRoot)).map((content) => path.join(cacheRoot, content));
    await Promise.all(dirContents.map(async (dir) => {
        if (!(await fs.lstat(dir)).isDirectory()) {
            return;
        }
        const engineName = path.basename(dir);
        map[engineName] = path.join(dir, 'package');
    }));
    return map;
}
exports.getCacheByEngine = getCacheByEngine;
//# sourceMappingURL=packageRequester.js.map